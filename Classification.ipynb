{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZdiAbAGZV6F"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "g4cWlUufZXcg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.13.0.92-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from opencv-python) (2.3.5)\n",
      "Downloading opencv_python-4.13.0.92-cp37-abi3-win_amd64.whl (40.2 MB)\n",
      "   ---------------------------------------- 0.0/40.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.1/40.2 MB 14.4 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.2/40.2 MB 15.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 9.4/40.2 MB 16.6 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 12.1/40.2 MB 15.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.2/40.2 MB 17.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 18.1/40.2 MB 15.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.2/40.2 MB 15.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.2/40.2 MB 15.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 29.9/40.2 MB 16.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 33.0/40.2 MB 16.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.5/40.2 MB 17.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.1/40.2 MB 17.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.2/40.2 MB 15.4 MB/s  0:00:02\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.13.0.92\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     27\u001b[39m     plt.title(title)\n\u001b[32m     28\u001b[39m     plt.show()\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install opencv-python\n",
    "\n",
    "#IMPORT LIBRARY OF SEGMENTATION\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.morphology import extrema\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "def ShowImage(title, img, ctype):\n",
    "    plt.figure(figsize=(10, 10))      #SET THE FIGURE SIZE TO 10X10 INCHES\n",
    "    if ctype == 'bgr':\n",
    "        b, g, r = cv2.split(img)       #SPLIT IMAGE INTO B,G,R\n",
    "        rgb_img = cv2.merge([r, g, b])     #MERGE THE CHANNEL IN R,G,B ORDER\n",
    "        plt.imshow(rgb_img)\n",
    "    elif ctype == 'hsv':\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)    #CONVERT IMAGE HSV TO RGB(HUE,SATURATION,VALUE)\n",
    "        plt.imshow(rgb)\n",
    "    elif ctype == 'gray':\n",
    "        plt.imshow(img, cmap='gray')        #DISPLAY IN GRAP SCALE FORMAT\n",
    "    elif ctype == 'rgb':\n",
    "        plt.imshow(img)                     #DISPLAY IN RGB FORMAT\n",
    "    else:\n",
    "        raise Exception(\"Unknown colour type\")\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    image_path = next(iter(uploaded))\n",
    "    image = Image.open(io.BytesIO(uploaded[image_path]))\n",
    "\n",
    "    local_image_path = '/content/' + image_path\n",
    "    image.save(local_image_path)\n",
    "    print(f\"Image {image_path} uploaded successfully and saved as {local_image_path}!\")\n",
    "else:\n",
    "    print(\"No image uploaded, exiting...\")\n",
    "    exit()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "\n",
    "ShowImage('Brain MRI', gray, 'gray')\n",
    "\n",
    "# THRESHOLDING USING OTSU'S METHOD\n",
    "\n",
    "# OTSU'S METHOD AUTOMATICALLY CALCULATES THE OPTIMAL THRESHOLD VALUE TO SEPARATE THE FOREGROUND AND BACKGROUND\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "# DISPLAY THE THRESHOLDED IMAGE\n",
    "ShowImage('Thresholding image', thresh, 'gray')\n",
    "\n",
    "# CONNECTED COMPONENTS ANALYSIS\n",
    "\n",
    "# THIS STEP LABELS DIFFERENT CONNECTED COMPONENTS IN THE BINARY IMAGE. EACH CONNECTED COMPONENT GETS A UNIQUE LABEL.\n",
    "ret, markers = cv2.connectedComponents(thresh)\n",
    "\n",
    "# CALCULATE THE AREA TAKEN BY EACH COMPONENT, EXCLUDING THE BACKGROUND (LABEL 0)\n",
    "marker_area = [np.sum(markers == m) for m in range(np.max(markers)) if m != 0]\n",
    "\n",
    "# IDENTIFY THE LABEL OF THE LARGEST CONNECTED COMPONENT\n",
    "largest_component = np.argmax(marker_area) + 1  # ADD 1 BECAUSE LABEL 0 IS BACKGROUND\n",
    "\n",
    "# CREATE A MASK FOR THE LARGEST CONNECTED COMPONENT (WHICH CORRESPONDS TO THE BRAIN IN THIS CONTEXT)\n",
    "brain_mask = markers == largest_component\n",
    "\n",
    "# CREATE A COPY OF THE ORIGINAL IMAGE TO APPLY THE BRAIN MASK\n",
    "brain_out = img.copy()\n",
    "\n",
    "# REMOVE ALL REGIONS FROM THE IMAGE EXCEPT FOR THE LARGEST COMPONENT (BRAIN)\n",
    "brain_out[brain_mask == False] = (0, 0, 0)\n",
    "\n",
    "# NOISE REMOVAL\n",
    "\n",
    "img = cv2.imread(image_path)#READ THE IMAGE PATH\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # CONVERT THE IMAGE TO GRAYSCALE\n",
    "\n",
    "# APPLY INVERSE BINARY THRESHOLDING WITH OTSU'S METHOD\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "# MORPHOLOGICAL OPENING IS USED HERE TO REMOVE SMALL WHITE NOISE FROM THE FOREGROUND\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "# DEFINE THE SURE BACKGROUND AREA BY DILATING THE IMAGE\n",
    "# DILATION INCREASES THE WHITE REGION, HELPING TO DEFINE THE BACKGROUND MORE CLEARLY\n",
    "sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "# DEFINE THE SURE FOREGROUND AREA USING DISTANCE TRANSFORM\n",
    "# THE DISTANCE TRANSFORM CALCULATES THE DISTANCE FROM EACH PIXEL TO THE NEAREST ZERO PIXEL (BACKGROUND)\n",
    "dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "\n",
    "# THRESHOLD THE DISTANCE TRANSFORMED IMAGE TO GET THE SURE FOREGROUND\n",
    "ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "\n",
    "# CONVERT SURE FOREGROUND TO UINT8 FORMAT\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "# SUBTRACT THE SURE FOREGROUND FROM THE SURE BACKGROUND TO GET THE UNKNOWN REGION\n",
    "unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "\n",
    "# MARKER LABELING\n",
    "# LABEL THE SURE FOREGROUND, WITH LABELS STARTING FROM 1\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# INCREMENT ALL LABEL VALUES BY 1, SO THAT THE BACKGROUND IS LABELED AS 1 INSTEAD OF 0\n",
    "markers = markers + 1\n",
    "\n",
    "# MARK THE UNKNOWN REGION WITH ZERO\n",
    "markers[unknown == 255] = 0\n",
    "\n",
    "# APPLY WATERSHED ALGORITHM\n",
    "# THE WATERSHED ALGORITHM TREATS THE IMAGE LIKE A TOPOGRAPHIC MAP AND \"FLOODS\" REGIONS FROM THE MARKERS\n",
    "markers = cv2.watershed(img, markers)\n",
    "\n",
    "# MARK THE BOUNDARIES IDENTIFIED BY THE WATERSHED ALGORITHM\n",
    "# BOUNDARIES ARE MARKED WITH -1, SO WE COLOR THOSE PIXELS RED (255, 0, 0)\n",
    "img[markers == -1] = [255, 0, 0]\n",
    "\n",
    "# CONVERT THE IMAGE FROM HSV TO RGB (IF NEEDED)\n",
    "im1 = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "# DISPLAY THE WATERSHED-SEGMENTED IMAGE\n",
    "ShowImage('Watershed segmented image', im1, 'gray')\n",
    "\n",
    "# Required Libraries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image):\n",
    "    equalized_image = cv2.equalizeHist(image)\n",
    "    return equalized_image\n",
    "\n",
    "# Segmentation function\n",
    "def segment_image(image):\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(binary)\n",
    "    markers = markers + 1\n",
    "    unknown = cv2.subtract(binary, binary)\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(image_rgb, markers)\n",
    "    binary[markers == -1] = 0  # Mark boundaries\n",
    "\n",
    "    return binary\n",
    "\n",
    "# Remove small components\n",
    "def remove_small_components(segmented_image, min_size=100):\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(segmented_image, connectivity=8)\n",
    "    sizes = stats[1:, -1]\n",
    "    filtered_image = np.zeros_like(segmented_image)\n",
    "\n",
    "    for i in range(0, num_labels - 1):\n",
    "        if sizes[i] >= min_size:\n",
    "            filtered_image[labels == i + 1] = 255\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "# Calculate tumor volume and percentage\n",
    "def calculate_tumor_volume_for_image(image, pixel_spacing, slice_thickness):\n",
    "    preprocessed_img = preprocess_image(image)\n",
    "    segmented_image = segment_image(preprocessed_img)\n",
    "    filtered_image = remove_small_components(segmented_image)\n",
    "\n",
    "    tumor_pixels = np.sum(filtered_image == 255)\n",
    "    pixel_area = pixel_spacing[0] * pixel_spacing[1]\n",
    "    slice_area = tumor_pixels * pixel_area\n",
    "    tumor_volume = slice_area * slice_thickness\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    total_slice_area = total_pixels * pixel_area\n",
    "    total_volume = total_slice_area * slice_thickness\n",
    "    percentage_spread = (tumor_volume / total_volume) * 100\n",
    "\n",
    "    print(f\"Estimated Tumor Volume: {tumor_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Total Slice Volume: {total_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Percentage of Tumor Spread: {percentage_spread:.2f}%\")\n",
    "\n",
    "    return preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('/content/drive/Shareddrives/MUKESH_NO_PROJECT/SAVED MODELS/Brain_Tumors_Classifier_efficientnetb0.h5', compile=False)\n",
    "loaded_model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Function to classify the tumor\n",
    "def classify_image(image):\n",
    "    img = image.resize((224, 224))\n",
    "    img_array = keras_image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    class_labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Direct image path\n",
    "image_path = '/content/drive/Shareddrives/MUKESH_NO_PROJECT/brain/Testing/notumor/Te-noTr_0000.jpg'  # Replace with the actual path to your image\n",
    "\n",
    "# Load and preprocess the image\n",
    "try:\n",
    "    image = Image.open(image_path)\n",
    "    print(f\"Image {image_path} loaded successfully!\")\n",
    "\n",
    "    # Convert to grayscale\n",
    "    img_gray = np.array(image.convert('L'))\n",
    "\n",
    "    # Set your pixel spacing and slice thickness\n",
    "    pixel_spacing = (0.5, 0.5)  # Replace with actual pixel spacing (e.g., (0.5 mm, 0.5 mm))\n",
    "    slice_thickness = 2.0  # Replace with the actual slice thickness in mm\n",
    "\n",
    "    # Calculate tumor volume and percentage\n",
    "    preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread = calculate_tumor_volume_for_image(\n",
    "        img_gray, pixel_spacing, slice_thickness)\n",
    "\n",
    "    # Create a figure with multiple subplots\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # Subplot 1: Displaying the Grayscale Brain MRI Image\n",
    "    plt.subplot(1, 3, 1)  # 1 row, 3 columns, first position\n",
    "    plt.imshow(img_gray, cmap='gray')\n",
    "    plt.title('Brain MRI')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Subplot 2: Displaying the Thresholded Image\n",
    "    plt.subplot(1, 3, 2)  # 1 row, 3 columns, second position\n",
    "    plt.imshow(preprocessed_img, cmap='gray')\n",
    "    plt.title('Thresholded Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Subplot 3: Displaying the Watershed Segmented Image\n",
    "    plt.subplot(1, 3, 3)  # 1 row, 3 columns, third position\n",
    "    plt.imshow(segmented_image, cmap='gray')\n",
    "    plt.title('Watershed Segmented Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show the comparison\n",
    "    plt.show()\n",
    "\n",
    "    # Perform classification\n",
    "    predicted_class = classify_image(image)\n",
    "\n",
    "    # Display the predicted class\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted: {predicted_class}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {image_path} not found. Please check the path and try again.\")\n",
    "\n",
    "# Required Libraries\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image):\n",
    "    equalized_image = cv2.equalizeHist(image)\n",
    "    return equalized_image\n",
    "\n",
    "# Segmentation function\n",
    "def segment_image(image):\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(binary)\n",
    "    markers = markers + 1\n",
    "    unknown = cv2.subtract(binary, binary)\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(image_rgb, markers)\n",
    "    binary[markers == -1] = 0  # Mark boundaries\n",
    "\n",
    "    return binary\n",
    "\n",
    "# Remove small components\n",
    "def remove_small_components(segmented_image, min_size=100):\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(segmented_image, connectivity=8)\n",
    "    sizes = stats[1:, -1]\n",
    "    filtered_image = np.zeros_like(segmented_image)\n",
    "\n",
    "    for i in range(0, num_labels - 1):\n",
    "        if sizes[i] >= min_size:\n",
    "            filtered_image[labels == i + 1] = 255\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "# Calculate tumor volume and percentage\n",
    "def calculate_tumor_volume_for_image(image, pixel_spacing, slice_thickness):\n",
    "    preprocessed_img = preprocess_image(image)\n",
    "    segmented_image = segment_image(preprocessed_img)\n",
    "    filtered_image = remove_small_components(segmented_image)\n",
    "\n",
    "    tumor_pixels = np.sum(filtered_image == 255)\n",
    "    pixel_area = pixel_spacing[0] * pixel_spacing[1]\n",
    "    slice_area = tumor_pixels * pixel_area\n",
    "    tumor_volume = slice_area * slice_thickness\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    total_slice_area = total_pixels * pixel_area\n",
    "    total_volume = total_slice_area * slice_thickness\n",
    "    percentage_spread = (tumor_volume / total_volume) * 100\n",
    "\n",
    "    print(f\"Estimated Tumor Volume: {tumor_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Total Slice Volume: {total_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Percentage of Tumor Spread: {percentage_spread:.2f}%\")\n",
    "\n",
    "    return preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('/content/drive/Shareddrives/MUKESH_NO_PROJECT/SAVED MODELS/Brain_Tumors_Classifier.h5', compile=False)\n",
    "loaded_model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Function to classify the tumor\n",
    "def classify_image(image):\n",
    "    img = image.resize((224, 224))\n",
    "    img_array = keras_image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    class_labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Upload the image file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Check if an image was uploaded\n",
    "if uploaded:\n",
    "    image_path = next(iter(uploaded))\n",
    "    image = Image.open(io.BytesIO(uploaded[image_path]))\n",
    "\n",
    "    # Save the uploaded image to the local filesystem in Colab\n",
    "    local_image_path = '/content/' + image_path\n",
    "    image.save(local_image_path)\n",
    "    print(f\"Image {image_path} uploaded successfully and saved as {local_image_path}!\")\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img_gray = np.array(image.convert('L'))\n",
    "\n",
    "    # Set your pixel spacing and slice thickness\n",
    "    pixel_spacing = (0.5, 0.5)  # Replace with actual pixel spacing (e.g., (0.5 mm, 0.5 mm))\n",
    "    slice_thickness = 2.0  # Replace with the actual slice thickness in mm\n",
    "\n",
    "    # Calculate tumor volume and percentage\n",
    "    preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread = calculate_tumor_volume_for_image(\n",
    "        img_gray, pixel_spacing, slice_thickness)\n",
    "\n",
    "   # Create a figure with multiple subplots\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # Subplot 1: Displaying the Grayscale Brain MRI Image\n",
    "    plt.subplot(1, 3, 1)  # 1 row, 3 columns, first position\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "    plt.title('Brain MRI')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Subplot 2: Displaying the Thresholded Image\n",
    "    plt.subplot(1, 3, 2)  # 1 row, 3 columns, second position\n",
    "    plt.imshow(thresh, cmap='gray')\n",
    "    plt.title('Thresholded Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Subplot 3: Displaying the Watershed Segmented Image\n",
    "    plt.subplot(1, 3, 3)  # 1 row, 3 columns, third position\n",
    "    plt.imshow(im1, cmap='gray')\n",
    "    plt.title('Watershed Segmented Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show the comparison\n",
    "    plt.show()\n",
    "\n",
    "# Set your pixel spacing and slice thickness\n",
    "    pixel_spacing = (0.5, 0.5)  # Replace with actual pixel spacing (e.g., (0.5 mm, 0.5 mm))\n",
    "    slice_thickness = 2.0  # Replace with the actual slice thickness in mm\n",
    "\n",
    "    # Calculate tumor volume and percentage\n",
    "    preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread = calculate_tumor_volume_for_image(\n",
    "        img_gray, pixel_spacing, slice_thickness)\n",
    "\n",
    "\n",
    "    # Perform classification\n",
    "    predicted_class = classify_image(image)\n",
    "\n",
    "    # Display the predicted class\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted: {predicted_class}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No image uploaded, exiting...\")\n",
    "\n",
    "# Required Libraries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image):\n",
    "    equalized_image = cv2.equalizeHist(image)\n",
    "    return equalized_image\n",
    "\n",
    "# Segmentation function\n",
    "def segment_image(image):\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(binary)\n",
    "    markers = markers + 1\n",
    "    unknown = cv2.subtract(binary, binary)\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(image_rgb, markers)\n",
    "    binary[markers == -1] = 0  # Mark boundaries\n",
    "\n",
    "    return binary\n",
    "\n",
    "# Remove small components\n",
    "def remove_small_components(segmented_image, min_size=100):\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(segmented_image, connectivity=8)\n",
    "    sizes = stats[1:, -1]\n",
    "    filtered_image = np.zeros_like(segmented_image)\n",
    "\n",
    "    for i in range(0, num_labels - 1):\n",
    "        if sizes[i] >= min_size:\n",
    "            filtered_image[labels == i + 1] = 255\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "# Calculate tumor volume and percentage\n",
    "def calculate_tumor_volume_for_image(image, pixel_spacing, slice_thickness):\n",
    "    preprocessed_img = preprocess_image(image)\n",
    "    segmented_image = segment_image(preprocessed_img)\n",
    "    filtered_image = remove_small_components(segmented_image)\n",
    "\n",
    "    tumor_pixels = np.sum(filtered_image == 255)\n",
    "    pixel_area = pixel_spacing[0] * pixel_spacing[1]\n",
    "    slice_area = tumor_pixels * pixel_area\n",
    "    tumor_volume = slice_area * slice_thickness\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    total_slice_area = total_pixels * pixel_area\n",
    "    total_volume = total_slice_area * slice_thickness\n",
    "    percentage_spread = (tumor_volume / total_volume) * 100\n",
    "\n",
    "    return preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('/content/drive/Shareddrives/MUKESH_NO_PROJECT/SAVED MODELS/Brain_Tumors_Classifier_densenet.h5', compile=False)\n",
    "loaded_model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Function to classify the tumor\n",
    "def classify_image(image):\n",
    "    img = image.resize((224, 224))\n",
    "    img_array = keras_image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    class_labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    return predicted_class\n",
    "\n",
    "# Direct image path\n",
    "image_path = '/content/drive/Shareddrives/MUKESH_NO_PROJECT/brain/Testing/notumor/Te-noTr_0000.jpg'  # Replace with the actual path to your image\n",
    "\n",
    "# Load and preprocess the image\n",
    "try:\n",
    "    image = Image.open(image_path)\n",
    "    print(f\"Image {image_path} loaded successfully!\")\n",
    "\n",
    "    # Perform classification\n",
    "    predicted_class = classify_image(image)\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "    if predicted_class == \"No Tumor\":\n",
    "        print(\"No tumor detected in the image.\")\n",
    "    else:\n",
    "        # Convert to grayscale\n",
    "        img_gray = np.array(image.convert('L'))\n",
    "\n",
    "        # Set your pixel spacing and slice thickness\n",
    "        pixel_spacing = (0.5, 0.5)  # Replace with actual pixel spacing (e.g., (0.5 mm, 0.5 mm))\n",
    "        slice_thickness = 2.0  # Replace with the actual slice thickness in mm\n",
    "\n",
    "        # Calculate tumor volume and percentage\n",
    "        preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread = calculate_tumor_volume_for_image(\n",
    "            img_gray, pixel_spacing, slice_thickness)\n",
    "\n",
    "        print(f\"Estimated Tumor Volume: {tumor_volume:.2f} cubic millimeters\")\n",
    "        print(f\"Percentage of Tumor Spread: {percentage_spread:.2f}%\")\n",
    "\n",
    "        # Create a figure with multiple subplots\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        # Subplot 1: Displaying the Grayscale Brain MRI Image\n",
    "        plt.subplot(1, 3, 1)  # 1 row, 3 columns, first position\n",
    "        plt.imshow(img_gray, cmap='gray')\n",
    "        plt.title('Brain MRI')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Subplot 2: Displaying the Thresholded Image\n",
    "        plt.subplot(1, 3, 2)  # 1 row, 3 columns, second position\n",
    "        plt.imshow(preprocessed_img, cmap='gray')\n",
    "        plt.title('Thresholded Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Subplot 3: Displaying the Watershed Segmented Image\n",
    "        plt.subplot(1, 3, 3)  # 1 row, 3 columns, third position\n",
    "        plt.imshow(segmented_image, cmap='gray')\n",
    "        plt.title('Watershed Segmented Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Show the comparison\n",
    "        plt.show()\n",
    "\n",
    "        # Display the predicted class\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Predicted: {predicted_class}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {image_path} not found. Please check the path and try again.\")\n",
    "\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    Applies histogram equalization to improve contrast in grayscale MRI image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: numpy array, grayscale image of an MRI slice.\n",
    "\n",
    "    Returns:\n",
    "    - equalized_image: numpy array, contrast-enhanced image.\n",
    "    \"\"\"\n",
    "    equalized_image = cv2.equalizeHist(image)\n",
    "    return equalized_image\n",
    "\n",
    "def segment_image(image):\n",
    "    \"\"\"\n",
    "    Segments the tumor from a grayscale MRI image using thresholding,\n",
    "    watershed algorithm, and morphological operations.\n",
    "\n",
    "    Parameters:\n",
    "    - image: numpy array, grayscale image of an MRI slice.\n",
    "\n",
    "    Returns:\n",
    "    - segmented_image: numpy array, binary image with the tumor region.\n",
    "    \"\"\"\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(binary)\n",
    "    markers = markers + 1\n",
    "    unknown = cv2.subtract(binary, binary)\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(image_rgb, markers)\n",
    "    binary[markers == -1] = 0  # Mark boundaries\n",
    "\n",
    "    return binary\n",
    "\n",
    "def remove_small_components(segmented_image, min_size=100):\n",
    "    \"\"\"\n",
    "    Removes small components in the segmented binary image that are not part of the tumor.\n",
    "\n",
    "    Parameters:\n",
    "    - segmented_image: numpy array, binary image with the tumor region.\n",
    "    - min_size: int, minimum size of components to keep.\n",
    "\n",
    "    Returns:\n",
    "    - filtered_image: numpy array, binary image with small components removed.\n",
    "    \"\"\"\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(segmented_image, connectivity=8)\n",
    "    sizes = stats[1:, -1]  # Get sizes of all components except the background\n",
    "    filtered_image = np.zeros_like(segmented_image)\n",
    "\n",
    "    for i in range(0, num_labels - 1):\n",
    "        if sizes[i] >= min_size:\n",
    "            filtered_image[labels == i + 1] = 255\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "def calculate_tumor_volume_for_image(image_path, pixel_spacing, slice_thickness):\n",
    "    \"\"\"\n",
    "    Calculates the volume of a tumor from a segmented 2D MRI slice and the total slice volume.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: str, path to the MRI slice.\n",
    "    - pixel_spacing: tuple (float, float), pixel spacing in millimeters (e.g., (0.5, 0.5)).\n",
    "    - slice_thickness: float, slice thickness in millimeters.\n",
    "\n",
    "    Returns:\n",
    "    - volume: float, estimated tumor volume in cubic millimeters.\n",
    "    - percentage_spread: float, percentage of the slice volume occupied by the tumor.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Error reading image: {image_path}\")\n",
    "\n",
    "    preprocessed_img = preprocess_image(img)\n",
    "    segmented_image = segment_image(preprocessed_img)\n",
    "    segmented_image = remove_small_components(segmented_image)\n",
    "\n",
    "    tumor_pixels = np.sum(segmented_image == 255)\n",
    "    pixel_area = pixel_spacing[0] * pixel_spacing[1]  # mm^2\n",
    "    slice_area = tumor_pixels * pixel_area\n",
    "    tumor_volume = slice_area * slice_thickness\n",
    "\n",
    "    total_pixels = img.shape[0] * img.shape[1]\n",
    "    total_slice_area = total_pixels * pixel_area  # Total area of the slice in mm^2\n",
    "    total_volume = total_slice_area * slice_thickness  # Total volume in cubic millimeters\n",
    "\n",
    "    percentage_spread = (tumor_volume / total_volume) * 100\n",
    "\n",
    "    print(f\"Estimated Tumor Volume: {tumor_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Total Slice Volume: {total_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Percentage of Tumor Spread: {percentage_spread:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "    return tumor_volume, total_volume, percentage_spread\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Subplot 1: Displaying the Grayscale Brain MRI Image\n",
    "plt.subplot(1, 3, 1)  # 1 row, 3 columns, first position\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.title('Brain MRI')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 2: Displaying the Thresholded Image\n",
    "plt.subplot(1, 3, 2)  # 1 row, 3 columns, second position\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title('Thresholded Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 3: Displaying the Watershed Segmented Image\n",
    "plt.subplot(1, 3, 3)  # 1 row, 3 columns, third position\n",
    "plt.imshow(im1, cmap='gray')\n",
    "plt.title('Watershed Segmented Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the comparison\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Now you can use the local_image_path in the calculation function\n",
    "pixel_spacing = (0.5, 0.5)  # Replace with actual pixel spacing (e.g., (0.5 mm, 0.5 mm))\n",
    "slice_thickness = 2.0  # Replace with the actual slice thickness in mm\n",
    "\n",
    "# Calculate tumor volume for the single image and display results\n",
    "calculate_tumor_volume_for_image(local_image_path, pixel_spacing, slice_thickness)\n",
    "\n",
    "# Required Libraries\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image):\n",
    "    equalized_image = cv2.equalizeHist(image)\n",
    "    return equalized_image\n",
    "\n",
    "# Segmentation function\n",
    "def segment_image(image):\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(binary)\n",
    "    markers = markers + 1\n",
    "    unknown = cv2.subtract(binary, binary)\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(image_rgb, markers)\n",
    "    binary[markers == -1] = 0  # Mark boundaries\n",
    "\n",
    "    return binary\n",
    "# Required Libraries\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "# Skull stripping function\n",
    "def remove_skull(image):\n",
    "    # Apply Gaussian Blur to smooth the image\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Threshold the image to create a binary mask\n",
    "    _, binary_mask = cv2.threshold(blurred, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Use morphological operations to clean up the mask\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # Remove the skull from the original image\n",
    "    skull_stripped_image = cv2.bitwise_and(image, image, mask=binary_mask)\n",
    "\n",
    "    return skull_stripped_image, binary_mask\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image):\n",
    "    equalized_image = cv2.equalizeHist(image)\n",
    "    return equalized_image\n",
    "\n",
    "# Segmentation function\n",
    "def segment_image(image):\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(binary)\n",
    "    markers = markers + 1\n",
    "    unknown = cv2.subtract(binary, binary)\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(image_rgb, markers)\n",
    "    binary[markers == -1] = 0  # Mark boundaries\n",
    "\n",
    "    return binary\n",
    "\n",
    "# Remove small components\n",
    "def remove_small_components(segmented_image, min_size=100):\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(segmented_image, connectivity=8)\n",
    "    sizes = stats[1:, -1]\n",
    "    filtered_image = np.zeros_like(segmented_image)\n",
    "\n",
    "    for i in range(0, num_labels - 1):\n",
    "        if sizes[i] >= min_size:\n",
    "            filtered_image[labels == i + 1] = 255\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "# Calculate tumor volume and percentage\n",
    "def calculate_tumor_volume_for_image(image, pixel_spacing, slice_thickness):\n",
    "    preprocessed_img = preprocess_image(image)\n",
    "    segmented_image = segment_image(preprocessed_img)\n",
    "    filtered_image = remove_small_components(segmented_image)\n",
    "\n",
    "    tumor_pixels = np.sum(filtered_image == 255)\n",
    "    pixel_area = pixel_spacing[0] * pixel_spacing[1]\n",
    "    slice_area = tumor_pixels * pixel_area\n",
    "    tumor_volume = slice_area * slice_thickness\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    total_slice_area = total_pixels * pixel_area\n",
    "    total_volume = total_slice_area * slice_thickness\n",
    "    percentage_spread = (tumor_volume / total_volume) * 100\n",
    "\n",
    "    print(f\"Estimated Tumor Volume: {tumor_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Total Slice Volume: {total_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Percentage of Tumor Spread: {percentage_spread:.2f}%\")\n",
    "\n",
    "    return preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('/content/drive/Shareddrives/MUKESH_NO_PROJECT/SAVED MODELS/Brain_Tumors_Classifier_densenet.h5', compile=False)\n",
    "loaded_model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Function to classify the tumor\n",
    "def classify_image(image):\n",
    "    img = image.resize((224, 224))\n",
    "    img_array = keras_image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    class_labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Upload the image file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Check if an image was uploaded\n",
    "if uploaded:\n",
    "    image_path = next(iter(uploaded))\n",
    "    image = Image.open(io.BytesIO(uploaded[image_path]))\n",
    "\n",
    "    # Save the uploaded image to the local filesystem in Colab\n",
    "    local_image_path = '/content/' + image_path\n",
    "    image.save(local_image_path)\n",
    "    print(f\"Image {image_path} uploaded successfully and saved as {local_image_path}!\")\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img_gray = np.array(image.convert('L'))\n",
    "\n",
    "    # Remove the skull\n",
    "    skull_stripped_image, skull_mask = remove_skull(img_gray)\n",
    "\n",
    "    # Set your pixel spacing and slice thickness\n",
    "    pixel_spacing = (0.5, 0.5)  # Replace with actual pixel spacing (e.g., (0.5 mm, 0.5 mm))\n",
    "    slice_thickness = 2.0  # Replace with the actual slice thickness in mm\n",
    "\n",
    "    # Calculate tumor volume and percentage on the skull-stripped image\n",
    "    preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread = calculate_tumor_volume_for_image(skull_stripped_image, pixel_spacing, slice_thickness)\n",
    "\n",
    "    # Create a figure with multiple subplots\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # Subplot 1: Displaying the Skull Stripped Image\n",
    "    plt.subplot(1, 3, 1)  # 1 row, 3 columns, first position\n",
    "    plt.imshow(skull_stripped_image, cmap='gray')\n",
    "    plt.title('Skull Stripped Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Subplot 2: Displaying the Thresholded Image\n",
    "    plt.subplot(1, 3, 2)  # 1 row, 3 columns, second position\n",
    "    plt.imshow(segmented_image, cmap='gray')\n",
    "    plt.title('Segmented Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Subplot 3: Displaying the Filtered Image\n",
    "    plt.subplot(1, 3, 3)  # 1 row, 3 columns, third position\n",
    "    plt.imshow(filtered_image, cmap='gray')\n",
    "    plt.title('Filtered Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show the comparison\n",
    "    plt.show()\n",
    "\n",
    "    # Perform classification on the original image\n",
    "    predicted_class = classify_image(image)\n",
    "\n",
    "    # Display the predicted class\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted: {predicted_class}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No image uploaded, exiting...\")\n",
    "\n",
    "# Remove small components\n",
    "def remove_small_components(segmented_image, min_size=100):\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(segmented_image, connectivity=8)\n",
    "    sizes = stats[1:, -1]\n",
    "    filtered_image = np.zeros_like(segmented_image)\n",
    "\n",
    "    for i in range(0, num_labels - 1):\n",
    "        if sizes[i] >= min_size:\n",
    "            filtered_image[labels == i + 1] = 255\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "# Calculate tumor volume and percentage\n",
    "def calculate_tumor_volume_for_image(image, pixel_spacing, slice_thickness):\n",
    "    preprocessed_img = preprocess_image(image)\n",
    "    segmented_image = segment_image(preprocessed_img)\n",
    "    filtered_image = remove_small_components(segmented_image)\n",
    "\n",
    "    tumor_pixels = np.sum(filtered_image == 255)\n",
    "    pixel_area = pixel_spacing[0] * pixel_spacing[1]\n",
    "    slice_area = tumor_pixels * pixel_area\n",
    "    tumor_volume = slice_area * slice_thickness\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    total_slice_area = total_pixels * pixel_area\n",
    "    total_volume = total_slice_area * slice_thickness\n",
    "    percentage_spread = (tumor_volume / total_volume) * 100\n",
    "\n",
    "    print(f\"Estimated Tumor Volume: {tumor_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Total Slice Volume: {total_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Percentage of Tumor Spread: {percentage_spread:.2f}%\")\n",
    "\n",
    "    return preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('/content/drive/Shareddrives/MUKESH_NO_PROJECT/SAVED MODELS/Brain_Tumors_Classifier_efficientnetb0.h5', compile=False)\n",
    "loaded_model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Function to classify the tumor\n",
    "def classify_image(image):\n",
    "    img = image.resize((224, 224))\n",
    "    img_array = keras_image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    class_labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "    return predicted_class\n",
    "'''\n",
    "# Path to the uploaded image (from previous upload)\n",
    "local_image_path = '/content/drive/Shareddrives/MUKESH_NO_PROJECT/brain/Testing/notumor/Te-noTr_0000.jpg'  # Replace with the path from the previous upload\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open(local_image_path)\n",
    "img_gray = np.array(image.convert('L'))\n",
    "'''\n",
    "# Set your pixel spacing and slice thickness\n",
    "pixel_spacing = (0.5, 0.5)  # Replace with actual pixel spacing (e.g., (0.5 mm, 0.5 mm))\n",
    "slice_thickness = 2.0  # Replace with the actual slice thickness in mm\n",
    "\n",
    "# Calculate tumor volume and percentage\n",
    "preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread = calculate_tumor_volume_for_image(\n",
    "    img_gray, pixel_spacing, slice_thickness)\n",
    "\n",
    "# Create a figure with subplots\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(preprocessed_img, cmap='gray')\n",
    "plt.title('Preprocessed Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(segmented_image, cmap='gray')\n",
    "plt.title('Segmented Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(filtered_image, cmap='gray')\n",
    "plt.title('Filtered Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Perform classification\n",
    "predicted_class = classify_image(image)\n",
    "\n",
    "# Display the predicted class\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Predicted: {predicted_class}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Required Libraries\n",
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "# Improved Skull Stripping function\n",
    "def remove_skull(image):\n",
    "    # Convert to float32 for more precision during processing\n",
    "    image_float = image.astype(np.float32)\n",
    "\n",
    "    # Apply adaptive histogram equalization to enhance contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    equalized_image = clahe.apply(image.astype(np.uint8))\n",
    "\n",
    "    # Thresholding to create a binary mask\n",
    "    _, binary_mask = cv2.threshold(equalized_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Use morphological operations to improve the mask\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # Remove small components from the mask\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_mask, connectivity=8)\n",
    "    sizes = stats[1:, -1]  # Ignore the background label (0)\n",
    "    mask_filtered = np.zeros_like(binary_mask)\n",
    "\n",
    "    # Keep only the largest component, assuming it's the brain\n",
    "    largest_component = np.argmax(sizes) + 1\n",
    "    mask_filtered[labels == largest_component] = 255\n",
    "\n",
    "    # Remove the skull from the original image using the refined mask\n",
    "    skull_stripped_image = cv2.bitwise_and(image, image, mask=mask_filtered)\n",
    "\n",
    "    return skull_stripped_image, mask_filtered\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(image):\n",
    "    equalized_image = cv2.equalizeHist(image)\n",
    "    return equalized_image\n",
    "\n",
    "# Segmentation function\n",
    "def segment_image(image):\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(binary)\n",
    "    markers = markers + 1\n",
    "    unknown = cv2.subtract(binary, binary)\n",
    "    markers[unknown == 255] = 0\n",
    "\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    markers = cv2.watershed(image_rgb, markers)\n",
    "    binary[markers == -1] = 0  # Mark boundaries\n",
    "\n",
    "    return binary\n",
    "\n",
    "# Remove small components\n",
    "def remove_small_components(segmented_image, min_size=100):\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(segmented_image, connectivity=8)\n",
    "    sizes = stats[1:, -1]\n",
    "    filtered_image = np.zeros_like(segmented_image)\n",
    "\n",
    "    for i in range(0, num_labels - 1):\n",
    "        if sizes[i] >= min_size:\n",
    "            filtered_image[labels == i + 1] = 255\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "# Calculate tumor volume and percentage\n",
    "def calculate_tumor_volume_for_image(image, pixel_spacing, slice_thickness):\n",
    "    preprocessed_img = preprocess_image(image)\n",
    "    segmented_image = segment_image(preprocessed_img)\n",
    "    filtered_image = remove_small_components(segmented_image)\n",
    "\n",
    "    tumor_pixels = np.sum(filtered_image == 255)\n",
    "    pixel_area = pixel_spacing[0] * pixel_spacing[1]\n",
    "    slice_area = tumor_pixels * pixel_area\n",
    "    tumor_volume = slice_area * slice_thickness\n",
    "\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    total_slice_area = total_pixels * pixel_area\n",
    "    total_volume = total_slice_area * slice_thickness\n",
    "    percentage_spread = (tumor_volume / total_volume) * 100\n",
    "\n",
    "    print(f\"Estimated Tumor Volume: {tumor_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Total Slice Volume: {total_volume:.2f} cubic millimeters\")\n",
    "    print(f\"Percentage of Tumor Spread: {percentage_spread:.2f}%\")\n",
    "\n",
    "    return preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('/content/drive/Shareddrives/MUKESH_NO_PROJECT/SAVED MODELS/Brain_Tumors_Classifier_densenet.h5', compile=False)\n",
    "loaded_model.compile(optimizer=Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Function to classify the tumor\n",
    "def classify_image(image):\n",
    "    img = image.resize((224, 224))\n",
    "    img_array = keras_image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    predictions = loaded_model.predict(img_array)\n",
    "    class_labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "    return predicted_class\n",
    "\n",
    "# Upload the image file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Check if an image was uploaded\n",
    "if uploaded:\n",
    "    image_path = next(iter(uploaded))\n",
    "    image = Image.open(io.BytesIO(uploaded[image_path]))\n",
    "\n",
    "    # Save the uploaded image to the local filesystem in Colab\n",
    "    local_image_path = '/content/' + image_path\n",
    "    image.save(local_image_path)\n",
    "    print(f\"Image {image_path} uploaded successfully and saved as {local_image_path}!\")\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img_gray = np.array(image.convert('L'))\n",
    "\n",
    "    # Remove the skull\n",
    "    skull_stripped_image, skull_mask = remove_skull(img_gray)\n",
    "\n",
    "    # Set your pixel spacing and slice thickness\n",
    "    pixel_spacing = (0.5, 0.5)  # Replace with actual pixel spacing (e.g., (0.5 mm, 0.5 mm))\n",
    "    slice_thickness = 2.0  # Replace with the actual slice thickness in mm\n",
    "\n",
    "    # Calculate tumor volume and percentage on the skull-stripped image\n",
    "    preprocessed_img, segmented_image, filtered_image, tumor_volume, total_volume, percentage_spread = calculate_tumor_volume_for_image(\n",
    "        skull_stripped_image, pixel_spacing, slice_thickness)\n",
    "\n",
    "    # Create a figure with multiple subplots\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # Subplot 1: Displaying the Skull Stripped Image\n",
    "    plt.subplot(1, 3, 1)  # 1 row, 3 columns, first position\n",
    "    plt.imshow(skull_stripped_image, cmap='gray')\n",
    "    plt.title('Skull Stripped Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Subplot 2: Displaying the Segmented Image\n",
    "    plt.subplot(1, 3, 2)  # 1 row, 3 columns, second position\n",
    "    plt.imshow(segmented_image, cmap='gray')\n",
    "    plt.title('Segmented Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Subplot 3: Displaying the Filtered Image\n",
    "    plt.subplot(1, 3, 3)  # 1 row, 3 columns, third position\n",
    "    plt.imshow(filtered_image, cmap='gray')\n",
    "    plt.title('Filtered Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show the comparison\n",
    "    plt.show()\n",
    "\n",
    "    # Perform classification on the original image\n",
    "    predicted_class = classify_image(image)\n",
    "\n",
    "    # Display the predicted class\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Predicted: {predicted_class}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No image uploaded, exiting...\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Subplot 1: Displaying the Grayscale Brain MRI Image\n",
    "plt.subplot(1, 3, 1)  # 1 row, 3 columns, first position\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.title('Brain MRI')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 2: Displaying the Thresholded Image\n",
    "plt.subplot(1, 3, 2)  # 1 row, 3 columns, second position\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title('Thresholded Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 3: Displaying the Watershed Segmented Image\n",
    "plt.subplot(1, 3, 3)  # 1 row, 3 columns, third position\n",
    "plt.imshow(im1, cmap='gray')\n",
    "plt.title('Watershed Segmented Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the comparison\n",
    "plt.show()\n",
    "\n",
    "#pixel region\n",
    "def on_click(event, img, ax):\n",
    "    if event.inaxes is not None:\n",
    "        # Get the x and y coordinates of the clicked point\n",
    "        x, y = int(event.xdata), int(event.ydata)\n",
    "\n",
    "        # Define the size of the region to highlight\n",
    "        size = 20  # Size of the square region around the clicked point\n",
    "\n",
    "        # Define the rectangle coordinates (top-left and bottom-right corners)\n",
    "        start_point = (max(x - size, 0), max(y - size, 0))  # Ensure points are within image boundaries\n",
    "        end_point = (min(x + size, img.shape[1]), min(y + size, img.shape[0]))\n",
    "\n",
    "        # Draw the rectangle on the image\n",
    "        img_with_rectangle = img.copy()\n",
    "        cv2.rectangle(img_with_rectangle, start_point, end_point, (255, 0, 0), 2)\n",
    "\n",
    "        # Clear the axis and display the updated image\n",
    "        ax.clear()\n",
    "        ax.imshow(img_with_rectangle, cmap='gray')\n",
    "        plt.draw()\n",
    "\n",
    "# Load and display the image\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(im1, cmap='gray')\n",
    "plt.title('Click on the image to highlight a region')\n",
    "\n",
    "# Connect the click event to the function\n",
    "fig.canvas.mpl_connect('button_press_event', lambda event: on_click(event, im1, ax))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Logic and code Shubham Danecha....\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Read and convert the grayscale MRI image\n",
    "# gray = cv2.imread('path_to_mri_image', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# # Apply thresholding to segment potential cancerous areas\n",
    "# # You can adjust the threshold value based on the image characteristics\n",
    "# _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# # Applying Watershed or any segmentation technique on the image\n",
    "# # im1 should be the result of your segmentation process\n",
    "# im1 = cv2.watershed(gray, markers)  # Show Result\n",
    "# # Calculate the percentage of cancer spread in the thresholded image\n",
    "# # Count total pixels\n",
    "# total_pixels = thresh.size\n",
    "\n",
    "# # Count white pixels (assuming cancerous regions are white)\n",
    "# white_pixels = cv2.countNonZero(thresh)\n",
    "\n",
    "# # Calculate the percentage of the sprad\n",
    "# cancer_spread_percentage = (white_pixels / total_pixels) * 100\n",
    "\n",
    "# print(f\"Cancer Spread Percentage: {cancer_spread_percentage:.2f}%\")\n",
    "\n",
    "# # Displaying the results with subplots\n",
    "# plt.figure(figsize=(20, 10))\n",
    "\n",
    "# # Subplot 1: Display the grayscale brain MRI image\n",
    "# plt.subplot(1, 3, 1)  # 1 row, 3 columns, first position\n",
    "# plt.imshow(gray, cmap='gray')\n",
    "# plt.title('Brain MRI')\n",
    "# plt.axis('off')\n",
    "\n",
    "# # Subplot 2: Display the thresholded image\n",
    "# plt.subplot(1, 3, 2)  # 1 row, 3 columns, second position\n",
    "# plt.imshow(thresh, cmap='gray')\n",
    "# plt.title('Thresholding Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# # Subplot 3: Display the watershed segmented image\n",
    "# plt.subplot(1, 3, 3)  # 1 row, 3 columns, third position\n",
    "# plt.imshow(im1, cmap='gray')\n",
    "# plt.title('Watershed Segmented Image')\n",
    "# plt.axis('off')\n",
    "\n",
    "# # Show the comparison\n",
    "# plt.show()\n",
    "\n",
    "# # Calculate the percentage of cancer spread\n",
    "# total_pixels = thresh.size  # Total number of pixels\n",
    "# cancer_pixels = cv2.countNonZero(thresh)  # Count non-zero pixels representing cancer\n",
    "\n",
    "# percentage_cancer_spread = (cancer_pixels / total_pixels) * 100\n",
    "\n",
    "# print(f\"Percentage of Cancer Spread: {percentage_cancer_spread:.2f}%\")\n",
    "\n",
    "\n",
    "## New Update Code.....\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read and convert the grayscale MRI image\n",
    "gray = cv2.imread('path_to_mri_image', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Read the ground truth mask (binary image)\n",
    "ground_truth_mask = cv2.imread('path_to_ground_truth_mask', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply thresholding to segment potential cancerous areas\n",
    "_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Create markers for watershed segmentation\n",
    "markers = np.zeros_like(gray)\n",
    "markers[thresh == 255] = 1  # Upper ground\n",
    "markers[thresh == 0] = 2     # Lower ground\n",
    "\n",
    "cv2.watershed(gray, markers)\n",
    "\n",
    "cancerous_regions = np.where(markers == -1, 255, 0).astype(np.uint8)\n",
    "\n",
    "total_pixels = gray.size  # Total number of pixels in the image\n",
    "cancer_pixels = cv2.countNonZero(cancerous_regions)\n",
    "\n",
    "# Calculate the percentage of cancer spread\n",
    "percentage_cancer_spread = (cancer_pixels / total_pixels) * 100\n",
    "\n",
    "# Calculate ground truth cancer spread percentage\n",
    "ground_truth_pixels = cv2.countNonZero(ground_truth_mask)\n",
    "percentage_ground_truth = (ground_truth_pixels / total_pixels) * 100\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "true_positive = cv2.countNonZero(cv2.bitwise_and(cancerous_regions, ground_truth_mask))\n",
    "false_positive = cancer_pixels - true_positive\n",
    "false_negative = cv2.countNonZero(ground_truth_mask) - true_positive\n",
    "\n",
    "# Precision, Recall, and F1-Score\n",
    "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Print results(Percentage)\n",
    "print(f\"Percentage of Cancer Spread: {percentage_cancer_spread:.2f}%\")\n",
    "print(f\"Ground Truth Percentage: {percentage_ground_truth:.2f}%\")\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1_score:.2f}\")\n",
    "\n",
    "# Displaying the results with subplots\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Subplot 1: Display the grayscale brain MRI image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.title('Brain MRI')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 2: Display the thresholded image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title('Thresholding Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 3: Display the watershed segmented image\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cancerous_regions, cmap='gray')\n",
    "plt.title('Watershed Segmented Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the comparison\n",
    "plt.show()\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read and convert the grayscale MRI image\n",
    "gray = cv2.imread('/content/drive/Shareddrives/MUKESH_NO_PROJECT/Untitled folder (1)/Tr-me_0054.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if image is loaded correctly\n",
    "if gray is None:\n",
    "    raise FileNotFoundError(\"The image file could not be found. Please check the file path.\")\n",
    "\n",
    "# Read the ground truth mask (binary image)\n",
    "ground_truth_mask = cv2.imread('/content/drive/Shareddrives/MUKESH_NO_PROJECT/Untitled folder/Tr-me_0054.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Check if ground truth mask is loaded correctly\n",
    "if ground_truth_mask is None:\n",
    "    raise FileNotFoundError(\"The ground truth mask file could not be found. Please check the file path.\")\n",
    "\n",
    "# Apply thresholding to segment potential cancerous areas\n",
    "_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Create markers for watershed segmentation\n",
    "markers = np.zeros_like(gray, dtype=np.int32)\n",
    "markers[thresh == 255] = 1  # Foreground\n",
    "markers[thresh == 0] = 2    # Background\n",
    "\n",
    "# Convert grayscale image to BGR for watershed\n",
    "gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Apply the watershed algorithm\n",
    "cv2.watershed(gray_bgr, markers)\n",
    "\n",
    "# Extract the segmented regions (cancerous areas)\n",
    "cancerous_regions = np.where(markers == -1, 255, 0).astype(np.uint8)\n",
    "\n",
    "# Calculate pixel statistics\n",
    "total_pixels = gray.size  # Total number of pixels in the image\n",
    "cancer_pixels = cv2.countNonZero(cancerous_regions)\n",
    "\n",
    "# Calculate the percentage of cancer spread\n",
    "percentage_cancer_spread = (cancer_pixels / total_pixels) * 100\n",
    "\n",
    "# Calculate ground truth cancer spread percentage\n",
    "ground_truth_pixels = cv2.countNonZero(ground_truth_mask)\n",
    "percentage_ground_truth = (ground_truth_pixels / total_pixels) * 100\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "true_positive = cv2.countNonZero(cv2.bitwise_and(cancerous_regions, ground_truth_mask))\n",
    "false_positive = cancer_pixels - true_positive\n",
    "false_negative = ground_truth_pixels - true_positive\n",
    "\n",
    "# Precision, Recall, and F1-Score\n",
    "precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "# Print results (Percentage)\n",
    "print(f\"Percentage of Cancer Spread: {percentage_cancer_spread:.2f}%\")\n",
    "print(f\"Ground Truth Percentage: {percentage_ground_truth:.2f}%\")\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1_score:.2f}\")\n",
    "\n",
    "# Displaying the results with subplots\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Subplot 1: Display the grayscale brain MRI image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(gray, cmap='gray')\n",
    "plt.title('Brain MRI')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 2: Display the thresholded image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(thresh, cmap='gray')\n",
    "plt.title('Thresholding Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Subplot 3: Display the watershed segmented image\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(cancerous_regions, cmap='gray')\n",
    "plt.title('Watershed Segmented Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the comparison\n",
    "plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data Augmentation and Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Use 20% for validation\n",
    ")\n",
    "\n",
    "# Train and Validation Data Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/content/drive/Shareddrives/MUKESH_NO_PROJECT/brain/Training',               # Replace with the path to your dataset\n",
    "    target_size=(224, 224),       # Resize images to 224x224\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',     # Multi-class classification\n",
    "    subset='training'             # Training subset\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    '/content/drive/Shareddrives/MUKESH_NO_PROJECT/brain/Training',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'           # Validation subset\n",
    ")\n",
    "\n",
    "# Load EfficientNetB0 Model\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the Model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),  # Replace Flatten with GAP for better generalization\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')  # 4 classes -> output layer with 4 neurons\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',  # Loss function for multi-class classification\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Save the Model\n",
    "model.save('efficientnetb0_brain_tumor_model.h5')\n",
    "\n",
    "# Evaluate the Model\n",
    "loss, accuracy = model.evaluate(val_generator)\n",
    "print(f\"Validation Loss: {loss}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQFImMP5xYLI"
   },
   "outputs": [],
   "source": [
    "#import gpu\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ec9W6VuZUsy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmXsWTLMQm55"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0OwjooKbtgF"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXkBR82CqOZ7",
    "outputId": "d85a3e04-bb8c-4a95-ecbc-55ea40d63ba3"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4DLQSskb01D"
   },
   "outputs": [],
   "source": [
    "# Lib for preprocessing\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHjp5Jaab2m3",
    "outputId": "66279771-0f88-4884-b6d5-3417d229111c"
   },
   "outputs": [],
   "source": [
    "# Lib for model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam , Adamax\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZZb0_0Ob5YP"
   },
   "outputs": [],
   "source": [
    "folder_training = r\"/content/drive/Shareddrives/MUKESH_NO_PROJECT/brain/Training\"\n",
    "Path = []\n",
    "Labels = []\n",
    "\n",
    "#to get the path for each Img :\n",
    "\n",
    "folders_path = os.listdir(folder_training)\n",
    "for img in folders_path :\n",
    "    FolderPath = os.path.join(folder_training, img)\n",
    "    FolderName = os.listdir(FolderPath)\n",
    "    for path in FolderName :\n",
    "        Images_path = os.path.join(FolderPath, path)\n",
    "\n",
    "        Path.append(Images_path)\n",
    "        Labels.append(img)\n",
    "\n",
    "# to creat DataFrame\n",
    "Pseries = pd.Series(Path, name = \"Img_Path\")\n",
    "Lseries = pd.Series(Labels, name = \"Img_label\")\n",
    "df_train = pd.concat([Pseries, Lseries], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWRe-iWphTNv"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "21q_uTM0b84_",
    "outputId": "e4332258-4401-4588-c38b-798cf8a00f21"
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLVEGwHlb_Af"
   },
   "outputs": [],
   "source": [
    "folder_test = r\"/content/drive/Shareddrives/MUKESH_NO_PROJECT/brain/Testing\"\n",
    "Path = []\n",
    "Labels = []\n",
    "\n",
    "# To get the path for each image in the test set:\n",
    "\n",
    "folders_path = os.listdir(folder_test)  # Use folder_test here\n",
    "for img in folders_path:\n",
    "    FolderPath = os.path.join(folder_test, img)  # Use folder_test here\n",
    "    FolderName = os.listdir(FolderPath)\n",
    "    for path in FolderName:\n",
    "        Images_path = os.path.join(FolderPath, path)\n",
    "\n",
    "        Path.append(Images_path)\n",
    "        Labels.append(img)\n",
    "\n",
    "# To create DataFrame\n",
    "Pseries = pd.Series(Path, name = \"Img_Path\")\n",
    "Lseries = pd.Series(Labels, name = \"Img_label\")\n",
    "df_test = pd.concat([Pseries, Lseries], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "MCm-mdPocBfI",
    "outputId": "0e58d69a-6580-4b77-9550-b9111859d6cf"
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLBwLg34cEVn"
   },
   "outputs": [],
   "source": [
    "valid_df, test_df = train_test_split(df_test, train_size=0.5, shuffle= True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3LrRSYDcRLo",
    "outputId": "204183f9-b8a2-479c-f6ac-06b4f1d8b508"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m batch_size = \u001b[32m16\u001b[39m\n\u001b[32m      2\u001b[39m img_size = (\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m tr_gen = \u001b[43mImageDataGenerator\u001b[49m()\n\u001b[32m      5\u001b[39m ts_gen = ImageDataGenerator()\n\u001b[32m      7\u001b[39m train_generator = tr_gen.flow_from_dataframe(\n\u001b[32m      8\u001b[39m     df_train,\n\u001b[32m      9\u001b[39m     x_col=\u001b[33m'\u001b[39m\u001b[33mImg_Path\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# Use the correct column name for file paths\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     batch_size=batch_size\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "img_size = (224, 224)\n",
    "\n",
    "tr_gen = ImageDataGenerator()\n",
    "ts_gen = ImageDataGenerator()\n",
    "\n",
    "train_generator = tr_gen.flow_from_dataframe(\n",
    "    df_train,\n",
    "    x_col='Img_Path',  # Use the correct column name for file paths\n",
    "    y_col='Img_label', # Use the correct column name for labels\n",
    "    target_size=img_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "valid_generator = ts_gen.flow_from_dataframe(\n",
    "    valid_df,\n",
    "    x_col='Img_Path',  # Use the correct column name for file paths\n",
    "    y_col='Img_label', # Use the correct column name for labels\n",
    "    target_size=img_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_generator = ts_gen.flow_from_dataframe(\n",
    "    df_test,\n",
    "    x_col='Img_Path',  # Use the correct column name for file paths\n",
    "    y_col='Img_label', # Use the correct column name for labels\n",
    "    target_size=img_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "l1hKEUMtcSE_",
    "outputId": "abd70a30-849a-49c0-8bfd-e4956ec0604b"
   },
   "outputs": [],
   "source": [
    "# Dictionary mapping class names to indices\n",
    "gen_dict = train_generator.class_indices\n",
    "# List of class names\n",
    "classes = list(gen_dict.keys())\n",
    "\n",
    "# Fetch a batch of images and labels\n",
    "images, labels = next(train_generator)\n",
    "\n",
    "# Set up the figure size\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Loop through the first 20 images in the batch\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "\n",
    "    # Normalize image pixel values to [0, 1] range\n",
    "    image = images[i] / 255.0\n",
    "\n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # Get the class index and class name\n",
    "    index = np.argmax(labels[i])  # Get image index\n",
    "    class_name = classes[index]   # Get class of image\n",
    "\n",
    "    # Set the title with class name\n",
    "    plt.title(class_name, color='red', fontsize=20)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Adjust layout for better spacing between plots\n",
    "plt.tight_layout()\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OyGxB4encWJO",
    "outputId": "a045118a-574a-4783-d5a2-3c3d5c14b6d6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Define and compile the model\u001b[39;00m\n\u001b[32m      2\u001b[39m img_shape = (img_size[\u001b[32m0\u001b[39m], img_size[\u001b[32m1\u001b[39m], \u001b[32m3\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m class_count = \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_generator\u001b[49m.class_indices)  \u001b[38;5;66;03m# Make sure this is correct\u001b[39;00m\n\u001b[32m      5\u001b[39m model = Sequential([\n\u001b[32m      6\u001b[39m     Conv2D(filters=\u001b[32m64\u001b[39m, kernel_size=(\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), padding=\u001b[33m\"\u001b[39m\u001b[33msame\u001b[39m\u001b[33m\"\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m, input_shape=img_shape),\n\u001b[32m      7\u001b[39m     Conv2D(filters=\u001b[32m64\u001b[39m, kernel_size=(\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), padding=\u001b[33m\"\u001b[39m\u001b[33msame\u001b[39m\u001b[33m\"\u001b[39m, activation=\u001b[33m\"\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     Dense(class_count, activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m)  \u001b[38;5;66;03m# Ensure class_count is correct\u001b[39;00m\n\u001b[32m     33\u001b[39m ])\n\u001b[32m     35\u001b[39m model.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Define and compile the model\n",
    "img_shape = (img_size[0], img_size[1], 3)\n",
    "class_count = len(train_generator.class_indices)  # Make sure this is correct\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\", input_shape=img_shape),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dense(class_count, activation='softmax')  # Ensure class_count is correct\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "epBreRyzcaGn"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m epochs =  \u001b[32m10\u001b[39m  \u001b[38;5;66;03m# number of all epochs in training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m history = \u001b[43mmodel\u001b[49m.fit(train_generator, epochs= epochs, verbose= \u001b[32m1\u001b[39m, validation_data= valid_generator, shuffle= \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs =  10  # number of all epochs in training\n",
    "\n",
    "history = model.fit(train_generator, epochs= epochs, verbose= 1, validation_data= valid_generator, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "49loyroAk7YI"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "rszwNNBiceK2"
   },
   "outputs": [],
   "source": [
    "# Define needed variables\n",
    "tr_acc = history.history['accuracy']\n",
    "tr_loss = history.history['loss']\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "index_loss = np.argmin(val_loss)\n",
    "val_lowest = val_loss[index_loss]\n",
    "index_acc = np.argmax(val_acc)\n",
    "acc_highest = val_acc[index_acc]\n",
    "\n",
    "Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize= (20, 8))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "u0_42ny7ci1v"
   },
   "outputs": [],
   "source": [
    "train_score = model.evaluate(train_generator, verbose= 1)\n",
    "valid_score = model.evaluate(valid_generator, verbose= 1)\n",
    "test_score = model.evaluate(test_generator, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "GUCEzpOScorQ"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_generator)\n",
    "y_pred = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vPb1tRX-HM1K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Bh7pz4mScqaG"
   },
   "outputs": [],
   "source": [
    "# Generate the class labels\n",
    "g_dict = test_generator.class_indices\n",
    "classes = list(g_dict.keys())\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap='Reds')  # Use red colormap\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "# Set tick marks and labels\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment='center',\n",
    "             color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into the figure area\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NsE_fwRDcsmH"
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_generator.classes, y_pred, target_names= classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YeOFHn3BV0eF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DbxM9x9NcweY"
   },
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save('/content/drive/MyDrive/your_shared_drive_path/Brain_Tumors_Classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CE5QvxNLXmE-"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "pk9_fdlNsf81"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/your_shared_drive_path/Brain_Tumors_Classifier.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kgkdv1IRc0ev"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('/content/drive/MyDrive/your_shared_drive_path/Brain_Tumors_Classifier.h5', compile=False)\n",
    "loaded_model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Image path\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the filename of the uploaded image\n",
    "\n",
    "image_path = next(iter(uploaded))\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Preprocess the image before prediction\n",
    "img = image.resize((224, 224))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Add batch dimension\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(img_array)\n",
    "class_labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']\n",
    "\n",
    "# Print the predicted class\n",
    "predicted_class = class_labels[np.argmax(predictions)]\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wmts6gXiHeUe"
   },
   "outputs": [],
   "source": [
    "# Example using VGG16\n",
    "from tensorflow.keras.applications import VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add your own classification layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(new_class_count, activation='softmax')(x) # new_class_count is the number of classes in your combined dataset\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XTHRq0nwHt_g"
   },
   "outputs": [],
   "source": [
    "# Example using VGG16\n",
    "from tensorflow.keras.applications import VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add your own classification layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "new_class_count = 4 # Replace with the actual number of classes in your dataset\n",
    "predictions = Dense(new_class_count, activation='softmax')(x) # new_class_count is the number of classes in your combined dataset\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hwTTj7N1QpGn"
   },
   "outputs": [],
   "source": [
    "# Import required libraries for Grad-CAM\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras import backend as K\n",
    "from PIL import Image\n",
    "\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('/content/drive/MyDrive/your_shared_drive_path/Brain_Tumors_Classifier.h5', compile=False)\n",
    "model.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load an example image\n",
    "uploaded = files.upload()\n",
    "image_path = next(iter(uploaded))\n",
    "img = Image.open(image_path)\n",
    "img = img.resize((224, 224))\n",
    "img_array = np.array(img)\n",
    "\n",
    "# Preprocess the image\n",
    "input_img = np.expand_dims(img_array, axis=0)\n",
    "input_img = preprocess_input(input_img)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(input_img)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "\n",
    "# Define a function to get the Grad-CAM\n",
    "def get_gradcam_heatmap(model, img_array, layer_name, class_idx):\n",
    "    grad_model = Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, class_idx]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        conv_outputs[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = np.mean(conv_outputs, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "# Get the heatmap\n",
    "last_conv_layer_name = 'block5_conv3'  # Adjust this depending on your model\n",
    "heatmap = get_gradcam_heatmap(model, input_img, last_conv_layer_name, predicted_class)\n",
    "\n",
    "# Display the heatmap on the image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_array)\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_array)\n",
    "plt.imshow(heatmap, cmap='jet', alpha=0.5)  # Overlay heatmap with red color\n",
    "plt.title('Tumor Detection with Grad-CAM')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "POYju4aIRZUi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from google.colab import files\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Load the model architecture and weights\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Adding custom layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)  # Ensure this matches the number of classes in your dataset\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_weights('/content/drive/MyDrive/your_shared_drive_path/Brain_Tumors_Classifier.h5')\n",
    "\n",
    "# Load and preprocess the image\n",
    "uploaded = files.upload()\n",
    "image_path = next(iter(uploaded))\n",
    "img = Image.open(image_path)\n",
    "img = img.resize((224, 224))\n",
    "img_array = np.array(img)\n",
    "\n",
    "input_img = np.expand_dims(img_array, axis=0)\n",
    "input_img = preprocess_input(input_img)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(input_img)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "\n",
    "# Function to get Grad-CAM heatmap\n",
    "def get_gradcam_heatmap(model, img_array, layer_name, class_idx):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, class_idx]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        conv_outputs[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = np.mean(conv_outputs, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "# Get the heatmap\n",
    "last_conv_layer_name = 'block5_conv3'  # Adjust this depending on your model\n",
    "heatmap = get_gradcam_heatmap(model, input_img, last_conv_layer_name, predicted_class)\n",
    "\n",
    "# Display the heatmap on the image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_array)\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_array)\n",
    "plt.imshow(heatmap, cmap='jet', alpha=0.5)  # Overlay heatmap with red color\n",
    "plt.title('Tumor Detection with Grad-CAM')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6NS4cljkR-G9"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from PIL import Image\n",
    "from google.colab import files\n",
    "\n",
    "# Upload an image file\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model('/content/drive/MyDrive/your_shared_drive_path/Brain_Tumors_Classifier.h5', compile=False)\n",
    "model.compile(optimizer='adamax', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load an example image\n",
    "image_path = next(iter(uploaded))\n",
    "img = Image.open(image_path)\n",
    "img = img.resize((224, 224))\n",
    "img_array = np.array(img)\n",
    "\n",
    "# Preprocess the image\n",
    "input_img = np.expand_dims(img_array, axis=0)\n",
    "input_img = tf.keras.applications.vgg16.preprocess_input(input_img)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(input_img)\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "\n",
    "# Ensure the model has been called at least once before creating the Grad-CAM\n",
    "_ = model(input_img)\n",
    "\n",
    "# Function to find the last Conv2D layer in the model\n",
    "def get_last_conv_layer(model):\n",
    "    for layer in reversed(model.layers):\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            return layer.name\n",
    "    raise ValueError(\"No Conv2D layer found in the model.\")\n",
    "\n",
    "# Define a function to get the Grad-CAM\n",
    "def get_gradcam_heatmap(model, img_array, layer_name, class_idx):\n",
    "    grad_model = Model(\n",
    "        inputs=[model.inputs],\n",
    "        outputs=[model.get_layer(layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, class_idx]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "\n",
    "    pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        conv_outputs[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = np.mean(conv_outputs, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "# Get the last convolutional layer name\n",
    "last_conv_layer_name = get_last_conv_layer(model)\n",
    "\n",
    "# Get the heatmap\n",
    "heatmap = get_gradcam_heatmap(model, input_img, last_conv_layer_name, predicted_class)\n",
    "\n",
    "# Display the heatmap on the image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_array)\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_array)\n",
    "plt.imshow(heatmap, cmap='jet', alpha=0.5)  # Overlay heatmap with red color\n",
    "plt.title('Tumor Detection with Grad-CAM')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKrRyXHvTNja"
   },
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "D-ElNgdpTMlA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from google.colab import files\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Define the model architecture\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Adding custom layers\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(4, activation='softmax')(x)  # Ensure this matches the number of classes in your dataset\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_weights('/content/drive/MyDrive/your_shared_drive_path/Brain_Tumors_Classifier.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7U4CruBTRGE"
   },
   "outputs": [],
   "source": [
    "jupyter nbconvert --to html /Downloads/Classification.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
